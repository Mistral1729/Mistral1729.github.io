<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.1 Transitional//EN">
<html>
	<head>	
		<meta charset="utf-8" />
  		<meta name="generator" content="pandoc" />
  		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  		<meta name="dcterms.date" content="2023-09-13" />
  		<title>Statistics 1</title>
		<link rel="icon" type="image/png" href="../../pictures/mpg.png">
		<style>
			code{white-space: pre-wrap;}
				span.smallcaps{font-variant: small-caps;}
				span.underline{text-decoration: underline;}
				div.column{display: inline-block; vertical-align: top; width: 50%;}
				div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
				ul.task-list{list-style: none;}
				div.csl-bib-body { }
				div.csl-entry {
				  clear: both;
				}
				.hanging div.csl-entry {
				  margin-left:2em;
				  text-indent:-2em;
				}
				div.csl-left-margin {
				  min-width:2em;
				  float:left;
				}
				div.csl-right-inline {
				  margin-left:2em;
				  padding-left:1em;
				}
				div.csl-indent {
				  margin-left: 2em;
				}  
		</style>
		<link rel="stylesheet" href="../../note_style.css">

		<script type="text/javascript" async src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
		</script>

		<script type="text/javascript">
			function toggleSolution(tag) {
				var x = document.getElementById("solution"+tag);
				if (x.style.display === "none") {
					x.style.display = "block";
				} else {
					x.style.display = "none";
				}
			}
		</script>
	</head>

	<body>
		<header id="title-block-header">
			<h1 class="title">Statistics 1</h1>
		</header>
		
		<nav id="TOC" role="doc-toc">
			<h3 id="toc-title">Contents</h3>
			<ol>
				<li>
                    <a href="#stats">Statistics</a>
                    <ol>
                        <li><a href="#stats#def">Basic definitions</a></li>
                        <li><a href="#stats#biv">Bivariate data</a></li>
						<li><a href="#stats#cov">Covariance</a></li>
                        <li><a href="#stats#corrcoeff">Correlation coefficient</a></li>
                    </ol>
                </li>
				<li><a href="#prob">Probability</a></li>
				<li><a href="#bibliography">References</a></li>
			</ol>
		</nav>

		<h2 id="course-content">Course Content</h2>
		<p>
			<b>Statistics</b> <br>
			Bivariate data, Scatter Diagram, Two-way frequency distribution, Marginal frequency distribution, Conditional frequency distribution, Covariance, Simple Correlation, 
			Correlation coefficient, Cauchy Schwartz inequality, Properties of correlation coefficient, Regression analysis, Least square analysis, Regression lines and their 
			properties, Rank data, Rank Correlation, Spearman's Rank Correlation - it's derivation and properties, Spearman's Rank Correlation with perfect agreement, Spearman's 
			Rank Correlation with perfect disagreement. <br>
			<b>Probability</b> <br>
			Random variables, Probability distribution, Cumulative Probability distribution, Probability mass function, Probability density function, Expectations, Mean, Variance, 
			Moment about a point, Raw moments, Central moments, Skewness, Kurtosis, Probability distribution function of two variables. <br>
			<b>Practical</b> <br>
			Calculation of correlation coefficient, Regression and Calculation of Spearman's Rank Correlation.
		</p>

        <h2 id="stats">Statistics</h2>
        <h3 id="stats#def">Basic definitions</h3>
        <p>
            <div class="lemma">
                <ol>
                    <li>\(\lvert x - a \rvert < \epsilon \iff -\epsilon < x - a < \epsilon \iff a - \epsilon < x < a + \epsilon \iff x \in (a - \epsilon,\ a + \epsilon). \)</li>
					<li>\(\lvert x y \rvert = \lvert x \rvert \cdot \lvert y \rvert\).</li>
                    <li>\(\lvert x + y \rvert \leq \lvert x \rvert + \lvert y \rvert\). (Triange Inequality.) </li>
                    <li>\(\lvert \lvert x \rvert - \lvert y \rvert \rvert \leq \lvert x - y \rvert.\)</li>
                    <li>\(\displaystyle (\sum_{i=1}^n a_{i}^2)(\sum_{i=1}^n b_{i}^2) \geq (\sum_{i=1}^n a_i b_i)^2\). (Cauchy-Schwarz Inequality.)</li> 
                </ol>
            </div>
			<div class="definition">
                <ol>
					Consider \(n\) pairs of values \(x_i\ \forall i = 1,\ ...,\ n \) of the variable \(x\). Then we define the following
                    <li>\(\displaystyle \bar{x} = \mu = \mathbb{E}[x] := \frac{1}{n} \sum_{i=1}^n x_i\). (Mean, or expectation.) </li>
                    <li>\(\displaystyle \text{Var}(x) := \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2 = \mathbb{E}[(x - \bar{x})^2]\). (Variance.) </li>
                    <li>\(\displaystyle \text{S}_x := \sqrt{\text{Var}(x)} = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2} \). (Standard deviation.)</li>
					<li>\(\displaystyle \text{MD}_{\bar{x}} := \mathbb{E}[\ \lvert x - \bar{x} \rvert\ ] = \frac{1}{n} \sum_{i=1}^n \lvert x_i - \bar{x} \rvert \). (Mean deviation about mean.)</li> 
                </ol>
            </div>
			<div class="theorem">
				Standard deviation cannot be less than the mean deviation about mean.
			</div>
			<small><i><a href="#solution#1" class="text" onclick="toggleSolution('#1')">Show proof</a></i></small>
			<div id="solution#1" class="proof" style="display: none;">
				Consider \(n\) pairs of values \(x_i\ \forall i = 1,\ ...,\ n \) of the variable \(x\). By definition, 
				\[\displaystyle
					\text{S}_x = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2}
				\]
				is the standard deviation of \(x\) and 
				\[\displaystyle
					\text{MD}_{\bar{x}} = \frac{1}{n} \sum_{i=1}^n \lvert x_i - \bar{x} \rvert
				\]
				is the mean deviation about mean of \(x\). We define 
				\[\displaystyle
					a_i = \lvert x_i - \bar{x} \rvert \ \forall i = 1,\ ...,\ n\\
					b_i = 1 \ \forall i = 1,\ ...,\ n
				\]
				then by the Cauchy-Schwarz inequality (Lemma 5), we have 
				\[\displaystyle
					(\sum_{i=1}^n a_{i}^2)(\sum_{i=1}^n b_{i}^2) \geq (\sum_{i=1}^n a_i b_i)^2 \\
					\iff (\sum_{i=1}^n {\lvert x_i - \bar{x} \rvert}^2)(\sum_{i=1}^n 1^2) \geq (\sum_{i=1}^n \lvert x_i - \bar{x} \rvert \cdot 1)^2 \\
					\iff (\sum_{i=1}^n (x_i - \bar{x})^2)n \geq (\sum_{i=1}^n \lvert x_i - \bar{x} \rvert)^2 \\
					\iff \frac{1}{n}(\sum_{i=1}^n (x_i - \bar{x})^2) \geq \frac{1}{n^2}(\sum_{i=1}^n \lvert x_i - \bar{x} \rvert)^2 \\
					\iff \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2} \geq \frac{1}{n} \sum_{i=1}^n \lvert x_i - \bar{x} \rvert \\
					\iff \text{S}_x \geq \text{MD}_{\bar{x}}.
				\]
			</div>
        </p>

		<h3 id="stats#biv">Bivariate data</h3>
		<p>
			
		</p>
		<h4>Correlation analysis</h4>
		<h4>Regression analysis</h4>
		<h4>Scatter or dot diagram</h4>

        <h3 id="stats#cov">Covariance</h3>
        <p>
            <div class="definition">
                Consider \(n\) pairs of values \((x_{i}, y_{i})\ (\forall i = 1,\ ...,\ n)\) of the variables \(x\) and \(y\). 
                Then  
                \[\displaystyle
                    \text{Cov}(x, y) := \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})
                \]
                is the <b>covariance of \(x\) and \(y\)</b>.
            </div>
        </p>

        <h3 id="stats#corrcoeff">Correlation coefficient</h3>
        <p>
            <div class="definition">
                Consider \(n\) pairs of values \((x_{i}, y_{i})\ (\forall i = 1,\ ...,\ n)\) of the variables \(x\) and \(y\). 
                Then  
                \[\displaystyle
                    r_{xy} := \frac{\text{Cov}(x, y)}{\sqrt{\text{Var}(x)\text{Var}(y)}}
                \]
                is the <b>correlation coefficient between the variables \(x\) and \(y\)</b>.
            </div>
            <div class="theorem">
                <ol style="list-style: lower-latin;">
                    <li>\(\displaystyle \text{Cov}(x, y) = \frac{1}{n} \sum_{i=1}^n x_i y_i - \bar{x}\bar{y}.\)</li>
                    <li>\(\displaystyle \text{Var}(x) = \frac{1}{n} \sum_{i=1}^n x_i^2 - \bar{x}^2.\)</li>
                    <li>\(\displaystyle \text{Var}(y) = \frac{1}{n} \sum_{i=1}^n y_i^2 - \bar{y}^2.\)</li>
                </ol>
            </div>
            <div class="theorem">
                Correlation coefficient of any two variables is a dimensionless quantity, <br>
                i.e. it's a pure number, <br>
                i.e. it's independent of any units of measurement.
            </div>
            <div class="theorem">
                Correlation coefficient of any two variables is symmetrical w.r.t. the variables, <br>
                i.e. \(r_{xy} = r_{yx}\).
            </div>
            <div class="theorem">
                The numerical value of the correlation coefficient is independent of the change of origin and 
                scale of the axis.
            </div>
        </p>

		<h2 id="prob">Probability</h2>

		<h1 class="unnumbered" id="bibliography">References</h1>
		
			<div id="refs" class="references csl-bib-body" role="doc-bibliography">
				<div id="rudin" class="csl-entry" role="doc-biblioentry">
                <div class="csl-left-margin">1. </div><div class="csl-right-inline">Walter Rudin, <em>Principles of Mathematical Analysis</em> (International Series in Pure and Applied Mathematics, 1976).</div>
			</div>
		<hr />
		
			<small>	
				<p class="date">
					Last updated on 13.09.2023.<br>
					<a href="../../index.html#wiki">Notes</a>
				</p>
			</small>
	</body>
</html>